{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = pd.read_csv('Xtrain.csv').drop(columns=['Unnamed: 0']).to_numpy()\n",
    "# columns_except_evi = np.arange(x_train.shape[1]) != 4\n",
    "# x_train_wo_evi = x_train[:, columns_except_evi]\n",
    "# y_train = pd.read_csv('ytrain.csv').drop(columns=['Unnamed: 0']).to_numpy().ravel()\n",
    "\n",
    "# x_val = pd.read_csv('Xval.csv').drop(columns=['Unnamed: 0']).to_numpy()\n",
    "# x_val_wo_evi = x_val[:, columns_except_evi]\n",
    "# y_val = pd.read_csv('yval.csv').drop(columns=['Unnamed: 0']).to_numpy().ravel()\n",
    "\n",
    "# # For RandomSeachCV, we will need to combine training and validation \n",
    "# # sets then specify which portion is training and which is validation\n",
    "# # Also, for the final performance evaluation, train on all of \n",
    "# # the training AND validation data\n",
    "# X_train_plus_val = np.concatenate((x_train, x_val), axis=0)\n",
    "# x_train_plus_val_wo_evi = X_train_plus_val[:, columns_except_evi]\n",
    "# y_train_plus_val = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "# # Create a predefined train/test split for RandomSearchCV (to be used later)\n",
    "# validation_fold = np.concatenate((-1 * np.ones(len(y_train)), np.zeros(len(y_val))))\n",
    "# train_val_split = PredefinedSplit(validation_fold)\n",
    "\n",
    "# x_test = pd.read_csv('XTopTestTrain.csv').drop(columns=['Unnamed: 0']).to_numpy()\n",
    "# x_test_wo_evi = x_test[:, columns_except_evi]\n",
    "# y_test = pd.read_csv('yTopTestTrain.csv').drop(columns=['Unnamed: 0']).to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.loadtxt(\"X_train.txt\")\n",
    "x_train_wo_evi = X_train[:, :256]\n",
    "y_train = np.loadtxt('y_train.txt')\n",
    "\n",
    "X_val = np.loadtxt(\"X_val.txt\")\n",
    "x_val_wo_evi = X_val[:, :256]\n",
    "y_val = np.loadtxt('y_val.txt')\n",
    "\n",
    "X_test = np.loadtxt(\"X_test.txt\")\n",
    "x_test_wo_evi = X_test[:, :256]\n",
    "y_test = np.loadtxt('y_test.txt')\n",
    "\n",
    "\n",
    "# For RandomSeachCV, we will need to combine training and validation \n",
    "# sets then specify which portion is training and which is validation\n",
    "# Also, for the final performance evaluation, train on all of \n",
    "# the training AND validation data\n",
    "X_train_plus_val = np.concatenate((X_train, X_val), axis=0)\n",
    "x_train_plus_val_wo_evi = X_train_plus_val[:, :256]\n",
    "y_train_plus_val = np.concatenate((y_train, y_val), axis=0)\n",
    "# Create a predefined train/test split for RandomSearchCV\n",
    "validation_fold = np.concatenate((-1 * np.ones(len(y_train)), np.zeros(len(y_val))))\n",
    "train_val_split = PredefinedSplit(validation_fold)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Linear Regression Baseline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. BASIC RANDOM FOREST WITH ALL BANDS (TABLE 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MSE: 462.1963941051408\n",
      "Training RMSE: 21.49875331513762\n",
      "Validation MSE: 4192.235738553124\n",
      "Validation RMSE: 64.74747669641748\n",
      "Test MSE: 4527.891000213601\n",
      "Test RMSE: 67.2896054395744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEFAULT RANDOM FOREST WITH ALL BANDS except EVI\n",
    "rf_model_base = RandomForestRegressor(random_state=1)\n",
    "\n",
    "rf_model_base.fit(x_train_wo_evi, y_train)\n",
    "\n",
    "print(f\"\"\"\n",
    "Training MSE: {mse(y_train, rf_model_base.predict(x_train_wo_evi))}\n",
    "Training RMSE: {np.sqrt(mse(y_train, rf_model_base.predict(x_train_wo_evi)))}\n",
    "Validation MSE: {mse(y_val, rf_model_base.predict(x_val_wo_evi))}\n",
    "Validation RMSE: {np.sqrt(mse(y_val, rf_model_base.predict(x_val_wo_evi)))}\n",
    "Test MSE: {mse(y_test, rf_model_base.predict(x_test_wo_evi))}\n",
    "Test RMSE: {np.sqrt(mse(y_test, rf_model_base.predict(x_test_wo_evi)))}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MSE: 1246.185298294376\n",
      "Training RMSE: 35.30134980839084\n",
      "Validation MSE: 4283.522352320251\n",
      "Validation RMSE: 65.44862376185041\n",
      "Test MSE: 4491.9414928468295\n",
      "Test RMSE: 67.0219478443206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xgboost WITH ALL BANDS except EVI\n",
    "import xgboost as xgb\n",
    "# XGBoost with all bands\n",
    "xgb_default = xgb.XGBRegressor() #tuning learning rate did not help?\n",
    "\n",
    "xgb_default.fit(x_train_wo_evi, y_train)\n",
    "\n",
    "print(f\"\"\"\n",
    "Training MSE: {mse(y_train, xgb_default.predict(x_train_wo_evi))}\n",
    "Training RMSE: {np.sqrt(mse(y_train, xgb_default.predict(x_train_wo_evi)))}\n",
    "Validation MSE: {mse(y_val, xgb_default.predict(x_val_wo_evi))}\n",
    "Validation RMSE: {np.sqrt(mse(y_val, xgb_default.predict(x_val_wo_evi)))}\n",
    "Test MSE: {mse(y_test, xgb_default.predict(x_test_wo_evi))}\n",
    "Test RMSE: {np.sqrt(mse(y_test, xgb_default.predict(x_test_wo_evi)))}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MSE: 452.75563768530196\n",
      "Training RMSE: 21.27805530788239\n",
      "Validation MSE: 4159.0897152675125\n",
      "Validation RMSE: 64.4910049174884\n",
      "Test MSE: 4547.302806571431\n",
      "Test RMSE: 67.43369192452265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEFAULT RANDOM FOREST WITH ALL BANDS with EVI\n",
    "rf_model_base = RandomForestRegressor(random_state=1)\n",
    "\n",
    "rf_model_base.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\"\"\n",
    "Training MSE: {mse(y_train, rf_model_base.predict(X_train))}\n",
    "Training RMSE: {np.sqrt(mse(y_train, rf_model_base.predict(X_train)))}\n",
    "Validation MSE: {mse(y_val, rf_model_base.predict(X_val))}\n",
    "Validation RMSE: {np.sqrt(mse(y_val, rf_model_base.predict(X_val)))}\n",
    "Test MSE: {mse(y_test, rf_model_base.predict(X_test))}\n",
    "Test RMSE: {np.sqrt(mse(y_test, rf_model_base.predict(X_test)))}\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. FINE TUNING RANDOM FOREST WITH ALL BANDS (LAST TWO CODE BLOCK - TABLE 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 30\u001b[0m\n\u001b[1;32m     19\u001b[0m random_search_wo_evi \u001b[39m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     20\u001b[0m     estimator\u001b[39m=\u001b[39mrf_model_ft_wo_evi,\n\u001b[1;32m     21\u001b[0m     param_distributions\u001b[39m=\u001b[39mhyperparameters_wo_evi,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[39m# Fit the random search object to the training data\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m random_search_wo_evi\u001b[39m.\u001b[39;49mfit(x_train_plus_val_wo_evi, y_train_plus_val)\n\u001b[1;32m     31\u001b[0m \u001b[39m# summarize results\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39mBest: \u001b[39m\u001b[39m{\u001b[39;00mrandom_search_wo_evi\u001b[39m.\u001b[39mbest_score_\u001b[39m}\u001b[39;00m\u001b[39m using \u001b[39m\u001b[39m{\u001b[39;00mrandom_search_wo_evi\u001b[39m.\u001b[39mbest_params_\u001b[39m}\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m\"\"\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1767\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1768\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1769\u001b[0m         ParameterSampler(\n\u001b[1;32m   1770\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[1;32m   1771\u001b[0m         )\n\u001b[1;32m   1772\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### FINE TUNING on all normalized features\n",
    "rf_model_ft_wo_evi = RandomForestRegressor(random_state=1)\n",
    "\n",
    "max_depth_wo_evi = list(np.linspace(20, 40, 21, dtype=int))\n",
    "max_depth_wo_evi.append(None)\n",
    "# Define the hyperparameters to tune\n",
    "\n",
    "hyperparameters_wo_evi = {\n",
    "    \"n_estimators\": np.linspace(100, 110, 5, dtype=int),\n",
    "    \"max_features\": [None],\n",
    "    \"max_depth\": max_depth_wo_evi,\n",
    "    # \"max_leaf_nodes\": np.linspace(2, 90, 89, dtype=int),\n",
    "    # \"min_samples_split\": np.linspace(2, 25, 24, dtype=int),\n",
    "    # \"min_samples_leaf\": np.linspace(1, 80, 80, dtype=int),\n",
    "    # \"bootstrap\": [True, False], #Random Search always returned True\n",
    "}\n",
    "\n",
    "# Define the random search object\n",
    "random_search_wo_evi = RandomizedSearchCV(\n",
    "    estimator=rf_model_ft_wo_evi,\n",
    "    param_distributions=hyperparameters_wo_evi,\n",
    "    n_iter=105,\n",
    "    cv=train_val_split,\n",
    "    # cv=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit the random search object to the training data\n",
    "random_search_wo_evi.fit(x_train_plus_val_wo_evi, y_train_plus_val)\n",
    "# summarize results\n",
    "print(f\"\"\"Best: {random_search_wo_evi.best_score_} using {random_search_wo_evi.best_params_}\n",
    "\"\"\")\n",
    "\n",
    "rf_model_tuned_wo_evi = RandomForestRegressor(**random_search_wo_evi.best_params_,random_state=1).fit(x_train_wo_evi, y_train)\n",
    "\n",
    "print(f\"\"\"\n",
    "Training MSE: {mse(y_train, rf_model_tuned_wo_evi.predict(x_train_wo_evi))}\n",
    "Training RMSE: {np.sqrt(mse(y_train, rf_model_tuned_wo_evi.predict(x_train_wo_evi)))}\n",
    "Validation MSE: {mse(y_val, rf_model_tuned_wo_evi.predict(x_val_wo_evi))}\n",
    "Validation RMSE: {np.sqrt(mse(y_val, rf_model_tuned_wo_evi.predict(x_val_wo_evi)))}\n",
    "Test MSE: {mse(y_test, rf_model_tuned_wo_evi.predict(x_test_wo_evi))}\n",
    "Test RMSE: {np.sqrt(mse(y_test, rf_model_tuned_wo_evi.predict(x_test_wo_evi)))}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.0021782424149086044 using {'n_estimators': 105, 'max_features': None, 'max_depth': 20}\n",
      "\n",
      "-0.013972 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 35}\n",
      "0.000035 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 22}\n",
      "0.002178 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 20}\n",
      "-0.014306 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 36}\n",
      "-0.009067 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 32}\n",
      "-0.010643 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 33}\n",
      "-0.004823 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 26}\n",
      "-0.008525 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 29}\n",
      "-0.017358 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 39}\n",
      "0.000162 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 22}\n",
      "-0.013618 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 35}\n",
      "-0.013995 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 36}\n",
      "0.001444 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 20}\n",
      "-0.014102 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 36}\n",
      "-0.000053 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 23}\n",
      "-0.011690 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 34}\n",
      "-0.012767 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 31}\n",
      "-0.012493 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 34}\n",
      "-0.014874 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': None}\n",
      "-0.007966 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 28}\n",
      "-0.000142 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 22}\n",
      "-0.006030 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 27}\n",
      "-0.009716 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 33}\n",
      "-0.005614 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 25}\n",
      "-0.005257 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 24}\n",
      "-0.004385 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 26}\n",
      "-0.009168 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 29}\n",
      "-0.014359 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 35}\n",
      "0.000076 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 23}\n",
      "-0.007366 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 28}\n",
      "-0.014829 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 37}\n",
      "-0.011704 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 38}\n",
      "0.001773 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 21}\n",
      "-0.004857 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 26}\n",
      "-0.012529 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 31}\n",
      "-0.010502 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 33}\n",
      "-0.005368 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 25}\n",
      "-0.007248 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 28}\n",
      "0.001281 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 21}\n",
      "-0.011627 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 30}\n",
      "-0.009013 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 32}\n",
      "-0.006321 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 27}\n",
      "-0.006100 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 27}\n",
      "-0.000018 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 23}\n",
      "-0.015182 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 40}\n",
      "-0.004832 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 26}\n",
      "-0.010843 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 33}\n",
      "0.001161 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 21}\n",
      "-0.007522 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 28}\n",
      "-0.010149 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 33}\n",
      "-0.012268 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 34}\n",
      "-0.005941 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 25}\n",
      "0.000064 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 23}\n",
      "-0.014797 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 37}\n",
      "-0.011699 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 38}\n",
      "-0.005848 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 25}\n",
      "0.001789 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 21}\n",
      "-0.016155 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 40}\n",
      "-0.008522 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 29}\n",
      "0.000320 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 22}\n",
      "-0.014719 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 35}\n",
      "-0.004431 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 24}\n",
      "0.001918 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 20}\n",
      "-0.000445 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 23}\n",
      "-0.006078 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 27}\n",
      "-0.014103 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 37}\n",
      "0.001472 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 21}\n",
      "-0.015027 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': None}\n",
      "-0.017685 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 39}\n",
      "-0.011863 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 38}\n",
      "-0.011587 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 30}\n",
      "-0.011757 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 30}\n",
      "-0.016960 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 39}\n",
      "-0.008573 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 29}\n",
      "-0.014085 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 36}\n",
      "-0.008292 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 32}\n",
      "-0.015113 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': None}\n",
      "-0.016345 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 40}\n",
      "-0.007500 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 28}\n",
      "-0.012810 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 31}\n",
      "-0.008552 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 29}\n",
      "-0.011584 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 38}\n",
      "-0.013309 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 31}\n",
      "-0.014797 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 35}\n",
      "-0.005015 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 26}\n",
      "-0.016276 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 40}\n",
      "-0.012729 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 31}\n",
      "-0.008657 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 32}\n",
      "-0.015774 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': None}\n",
      "-0.006681 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 27}\n",
      "-0.005169 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 25}\n",
      "-0.018010 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 39}\n",
      "0.001482 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 20}\n",
      "-0.012092 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 30}\n",
      "-0.005349 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 24}\n",
      "0.001416 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 20}\n",
      "-0.004525 (0.000000) with: {'n_estimators': 102, 'max_features': None, 'max_depth': 24}\n",
      "-0.015161 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 37}\n",
      "-0.016256 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 39}\n",
      "-0.011745 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': 34}\n",
      "-0.014069 (0.000000) with: {'n_estimators': 97, 'max_features': None, 'max_depth': 37}\n",
      "-0.014877 (0.000000) with: {'n_estimators': 100, 'max_features': None, 'max_depth': 36}\n",
      "-0.014805 (0.000000) with: {'n_estimators': 105, 'max_features': None, 'max_depth': None}\n",
      "-0.005502 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 24}\n",
      "-0.007924 (0.000000) with: {'n_estimators': 95, 'max_features': None, 'max_depth': 32}\n"
     ]
    }
   ],
   "source": [
    "### FINE TUNING on EVI bands\n",
    "rf_model_ft = RandomForestRegressor(random_state=1)\n",
    "\n",
    "\n",
    "max_depth = list(np.linspace(20, 40, 21, dtype=int))\n",
    "max_depth.append(None)\n",
    "# Define the hyperparameters to tune\n",
    "\n",
    "hyperparameters = {\n",
    "    \"n_estimators\": np.linspace(95, 105, 5, dtype=int),\n",
    "    \"max_features\": [None],\n",
    "    \"max_depth\": max_depth,\n",
    "    # \"max_leaf_nodes\": np.linspace(2, 50, 49, dtype=int),\n",
    "    # \"min_samples_split\": np.linspace(2, 25, 24, dtype=int),\n",
    "    # \"min_samples_leaf\": np.linspace(1, 30, 30, dtype=int),\n",
    "    # \"bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "# Define the random search object\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_model_ft,\n",
    "    param_distributions=hyperparameters,\n",
    "    n_iter=105,\n",
    "    cv=train_val_split,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit the random search object to the training data\n",
    "random_search.fit(X_train_plus_val, y_train_plus_val)\n",
    "# summarize results\n",
    "print(f\"\"\"Best: {random_search.best_score_} using {random_search.best_params_}\n",
    "\"\"\")\n",
    "means = random_search.cv_results_['mean_test_score']\n",
    "stds = random_search.cv_results_['std_test_score']\n",
    "params = random_search.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MSE: 1567.79639901647\n",
      "Training RMSE: 39.595408812341745\n",
      "Validation MSE: 1731.190936815756\n",
      "Validation RMSE: 41.60758268411848\n",
      "Test MSE: 4307.73812866046\n",
      "Test RMSE: 65.63336139998057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model_tuned = RandomForestRegressor(**random_search.best_params_,random_state=1).fit(X_train_plus_val, y_train_plus_val)\n",
    "\n",
    "print(f\"\"\"\n",
    "Training MSE: {mse(y_train, rf_model_tuned.predict(X_train))}\n",
    "Training RMSE: {np.sqrt(mse(y_train, rf_model_tuned.predict(X_train)))}\n",
    "Validation MSE: {mse(y_val, rf_model_tuned.predict(X_val))}\n",
    "Validation RMSE: {np.sqrt(mse(y_val, rf_model_tuned.predict(X_val)))}\n",
    "Test MSE: {mse(y_test, rf_model_tuned.predict(X_test))}\n",
    "Test RMSE: {np.sqrt(mse(y_test, rf_model_tuned.predict(X_test)))}\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. SPECTURAL BANDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned_parameters_rf = {'n_estimators': 105, 'max_features': None, 'max_depth': 20}\n",
    "\n",
    "# define a function to try different bands\n",
    "def try_bands(x_train: np.ndarray, x_val: np.ndarray, x_test: np.ndarray):\n",
    "    rf = RandomForestRegressor(\n",
    "        # **tuned_parameters_rf,\n",
    "        random_state=1).fit(x_train, y_train)\n",
    "    print(f\"\"\"\n",
    "    Training MSE: {mse(y_train, rf.predict(x_train))}\n",
    "    Training RMSE: {np.sqrt(mse(y_train, rf.predict(x_train)))}\n",
    "    Validation MSE: {mse(y_val, rf.predict(x_val))}\n",
    "    Validation RMSE: {np.sqrt(mse(y_val, rf.predict(x_val)))}\n",
    "    Test MSE: {mse(y_test, rf.predict(x_test))}\n",
    "    Test RMSE: {np.sqrt(mse(y_test, rf.predict(x_test)))}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training MSE: 455.5206926059722\n",
      "    Training RMSE: 21.34293074078563\n",
      "    Validation MSE: 4147.357015191159\n",
      "    Validation RMSE: 64.39997682601414\n",
      "    Test MSE: 4191.433815685806\n",
      "    Test RMSE: 64.74128370433974\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# RBG\n",
    "try_bands(x_train_wo_evi[:,17:64], x_val_wo_evi[:,17:64], x_test_wo_evi[:,17:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training MSE: 458.64206815753886\n",
      "    Training RMSE: 21.415930242638044\n",
      "    Validation MSE: 4190.5807992027285\n",
      "    Validation RMSE: 64.73469548242834\n",
      "    Test MSE: 4867.281111348097\n",
      "    Test RMSE: 69.76590221123853\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# No Coastal Aerosol\n",
    "try_bands(x_train_wo_evi[:,17:], x_val_wo_evi[:,17:], x_test_wo_evi[:,17:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25036, 240)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_wo_evi[:, np.r_[0:16, 32:256]].shape #no Blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training MSE: 462.2094971754447\n",
      "    Training RMSE: 21.49905805321351\n",
      "    Validation MSE: 4196.266437338757\n",
      "    Validation RMSE: 64.77859551841763\n",
      "    Test MSE: 4475.917193070232\n",
      "    Test RMSE: 66.90229587293871\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# No Blue\n",
    "try_bands(x_train_wo_evi[:, np.r_[0:16, 32:256]], x_val_wo_evi[:, np.r_[0:16, 32:256]], x_test_wo_evi[:, np.r_[0:16, 32:256]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training MSE: 461.6710918815953\n",
      "    Training RMSE: 21.486532802702147\n",
      "    Validation MSE: 4192.817289091982\n",
      "    Validation RMSE: 64.75196745344486\n",
      "    Test MSE: 4510.330752176373\n",
      "    Test RMSE: 67.15899606289818\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# No Green\n",
    "try_bands(x_train_wo_evi[:, np.r_[0:32, 48:256]], x_val_wo_evi[:, np.r_[0:32, 48:256]], x_test_wo_evi[:, np.r_[0:32, 48:256]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training MSE: 459.5435994385777\n",
      "    Training RMSE: 21.436968056107602\n",
      "    Validation MSE: 4192.80968415727\n",
      "    Validation RMSE: 64.751908729838\n",
      "    Test MSE: 4536.943275440376\n",
      "    Test RMSE: 67.35683540250668\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# No Red\n",
    "try_bands(x_train_wo_evi[:, np.r_[0:48, 64:256]], x_val_wo_evi[:, np.r_[0:48, 64:256]], x_test_wo_evi[:, np.r_[0:48, 64:256]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training MSE: 457.2574993544991\n",
      "    Training RMSE: 21.383580134170682\n",
      "    Validation MSE: 4170.841000838432\n",
      "    Validation RMSE: 64.58204859586317\n",
      "    Test MSE: 4548.188138096123\n",
      "    Test RMSE: 67.44025606487659\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# No Vegetation_Red_Edge\n",
    "try_bands(x_train_wo_evi[:, np.r_[0:64, 80:256]], x_val_wo_evi[:, np.r_[0:64, 80:256]], x_test_wo_evi[:, np.r_[0:64, 80:256]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training MSE: 459.6758325780287\n",
      "    Training RMSE: 21.440052065655735\n",
      "    Validation MSE: 4184.2021200265335\n",
      "    Validation RMSE: 64.68540886495605\n",
      "    Test MSE: 4496.730550443227\n",
      "    Test RMSE: 67.0576658588951\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# No Vegetation_Red_Edge 2\n",
    "try_bands(x_train_wo_evi[:, np.r_[0:80, 96:256]], x_val_wo_evi[:, np.r_[0:80, 96:256]], x_test_wo_evi[:, np.r_[0:80, 96:256]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training MSE: 460.2877855716123\n",
      "    Training RMSE: 21.454318576259006\n",
      "    Validation MSE: 4183.494782611296\n",
      "    Validation RMSE: 64.67994111477913\n",
      "    Test MSE: 4523.706489340344\n",
      "    Test RMSE: 67.25850495915252\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Vegetation_Red_Edge 3\n",
    "try_bands(x_train_wo_evi[:, np.r_[0:96, 112:256]], x_val_wo_evi[:, np.r_[0:96, 112:256]], x_test_wo_evi[:, np.r_[0:96, 112:256]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training MSE: 461.0005189778878\n",
      "    Training RMSE: 21.470922639185485\n",
      "    Validation MSE: 4198.862049209701\n",
      "    Validation RMSE: 64.79862690836667\n",
      "    Test MSE: 4596.254750726961\n",
      "    Test RMSE: 67.79568386502906\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# No NIR\n",
    "try_bands(x_train_wo_evi[:, np.r_[0:112, 128:256]], x_val_wo_evi[:, np.r_[0:112, 128:256]], x_test_wo_evi[:, np.r_[0:112, 128:256]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training MSE: 460.4022349759341\n",
      "    Training RMSE: 21.4569856917493\n",
      "    Validation MSE: 4164.223776543063\n",
      "    Validation RMSE: 64.53079711690428\n",
      "    Test MSE: 4537.31820718358\n",
      "    Test RMSE: 67.35961852017557\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# No Narrow NIR\n",
    "try_bands(x_train_wo_evi[:, np.r_[0:128, 144:256]], x_val_wo_evi[:, np.r_[0:128, 144:256]], x_test_wo_evi[:, np.r_[0:128, 144:256]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training MSE: 459.5198333833573\n",
      "    Training RMSE: 21.436413724859793\n",
      "    Validation MSE: 4181.307688458906\n",
      "    Validation RMSE: 64.66303185328466\n",
      "    Test MSE: 4522.040616116803\n",
      "    Test RMSE: 67.24611971048444\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# No water vapor\n",
    "try_bands(x_train_wo_evi[:, np.r_[0:144, 160:256]], x_val_wo_evi[:, np.r_[0:144, 160:256]], x_test_wo_evi[:, np.r_[0:144, 160:256]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training MSE: 459.5306456254078\n",
      "    Training RMSE: 21.436665916727996\n",
      "    Validation MSE: 4170.312150577251\n",
      "    Validation RMSE: 64.57795406001378\n",
      "    Test MSE: 4470.855320594862\n",
      "    Test RMSE: 66.86445483659358\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# no SWIR1\n",
    "try_bands(x_train_wo_evi[:, np.r_[0:160, 176:256]], x_val_wo_evi[:, np.r_[0:160, 176:256]], x_test_wo_evi[:, np.r_[0:160, 176:256]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training MSE: 460.4577072711947\n",
      "    Training RMSE: 21.45827829233265\n",
      "    Validation MSE: 4185.676323575913\n",
      "    Validation RMSE: 64.69680303984049\n",
      "    Test MSE: 4533.730668532853\n",
      "    Test RMSE: 67.33298351129892\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# no SWIR2\n",
    "try_bands(x_train_wo_evi[:, np.r_[0:176, 192:256]], x_val_wo_evi[:, np.r_[0:176, 192:256]], x_test_wo_evi[:, np.r_[0:176, 192:256]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Environmental factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training MSE: 460.9885446581468\n",
      "    Training RMSE: 21.470643787696417\n",
      "    Validation MSE: 4208.196193839221\n",
      "    Validation RMSE: 64.87061117208025\n",
      "    Test MSE: 4312.119656026667\n",
      "    Test RMSE: 65.66673172944324\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# no Cloud\n",
    "try_bands(x_train_wo_evi[:, np.r_[0:192, 208:256]], x_val_wo_evi[:, np.r_[0:192, 208:256]], x_test_wo_evi[:, np.r_[0:192, 208:256]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training MSE: 460.19613958208953\n",
      "    Training RMSE: 21.45218262979526\n",
      "    Validation MSE: 4170.42388352118\n",
      "    Validation RMSE: 64.57881915551863\n",
      "    Test MSE: 4531.637392623065\n",
      "    Test RMSE: 67.31743750784833\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# no Latitude\n",
    "try_bands(x_train_wo_evi[:, np.r_[0:224, 240:256]], x_val_wo_evi[:, np.r_[0:224, 240:256]], x_test_wo_evi[:, np.r_[0:224, 240:256]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training MSE: 460.18034125641486\n",
      "    Training RMSE: 21.451814404763407\n",
      "    Validation MSE: 4178.267520486809\n",
      "    Validation RMSE: 64.6395198039621\n",
      "    Test MSE: 4537.764995701152\n",
      "    Test RMSE: 67.36293488040104\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# no Longitude\n",
    "try_bands(x_train_wo_evi[:, :240], x_val_wo_evi[:, :240], x_test_wo_evi[:, :240])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
