{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import earthpy as et\n",
    "import earthpy.spatial as es\n",
    "import earthpy.plot as ep\n",
    "\n",
    "import rasterio as rio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -q  https://share.phys.ethz.ch/~pf/albecker/abc/09072022_1154_train.h5\n",
    "# !wget -q  https://share.phys.ethz.ch/~pf/albecker/abc/09072022_1154_val.h5\n",
    "# !wget -q https://share.phys.ethz.ch/~pf/albecker/abc/09072022_1154_test.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = h5py.File(\"09072022_1154_train.h5\", \"r\")\n",
    "validateset = h5py.File(\"09072022_1154_val.h5\", \"r\")\n",
    "testset = h5py.File(\"09072022_1154_test.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['agbd', 'cloud', 'images', 'lat', 'lon', 'scl']>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 15, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset['images'].shape[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_images = np.array(trainset['images'],dtype=np.float64)\n",
    "train_images = train_images.transpose(0,3,1,2)\n",
    "\n",
    "train_biomasses = np.array(trainset['agbd'],dtype=np.float64)\n",
    "\n",
    "# validate\n",
    "validate_images = np.array(validateset['images'],dtype=np.float64)\n",
    "validate_images = validate_images.transpose(0,3,1,2)\n",
    "validate_biomasses = np.array(validateset['agbd'],dtype=np.float64)\n",
    "\n",
    "# test \n",
    "test_images = np.array(testset['images'],dtype=np.float32)\n",
    "test_images = test_images.transpose(0,3,1,2)\n",
    "test_biomasses = np.array(testset['agbd'],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size (25036, 12, 15, 15) train lab size (25036,)\n",
      "\n",
      "validate dataset size (5174, 12, 15, 15) validate lab size (5174,)\n",
      "\n",
      "test dataset size (5190, 12, 15, 15) test lab size (5190,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train dataset size {train_images.shape} train lab size {train_biomasses.shape}\")\n",
    "print()\n",
    "print(f\"validate dataset size {validate_images.shape} validate lab size {validate_biomasses.shape}\")\n",
    "print()\n",
    "print(f\"test dataset size {test_images.shape} test lab size {test_biomasses.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 73.1272964477539\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Define the input image size and number of spectral bands\n",
    "input_size = (12, 15, 15)\n",
    "\n",
    "# Load a pre-trained ResNet50 model\n",
    "model = models.resnet50(weights='ResNet50_Weights.DEFAULT')\n",
    "\n",
    "# Replace the first convolutional layer to accept input with 12 spectral bands\n",
    "model.conv1 = nn.Conv2d(input_size[0], 64, kernel_size=7, stride=2, padding=0, bias=False)\n",
    "\n",
    "# Modify the classifier to output the desired number of classes (e.g., 1 for regression)\n",
    "num_classes = 1\n",
    "model.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "# Define a loss function (e.g., mean squared error)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "input_ = torch.from_numpy(train_images).float()\n",
    "output_ = torch.from_numpy(train_biomasses).float().view(-1, 1)\n",
    "\n",
    "# Pass the input tensor through the model to obtain the predicted output tensor\n",
    "output_tensor = model(input_)\n",
    "\n",
    "# Compute the loss between the predicted output tensor and the target tensor\n",
    "loss = criterion(output_tensor, output_)\n",
    "\n",
    "# Compute the root mean squared error (RMSE) between the predicted output tensor and the target tensor\n",
    "rmse = torch.sqrt(loss)\n",
    "\n",
    "# Print the RMSE value\n",
    "print('RMSE:', rmse.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], RMSE: 73.1131\n",
      "Epoch [2/10], RMSE: 72.9937\n",
      "Epoch [3/10], RMSE: 72.2937\n",
      "Epoch [4/10], RMSE: 71.2826\n",
      "Epoch [5/10], RMSE: 69.7239\n",
      "Epoch [6/10], RMSE: 68.2044\n",
      "Epoch [7/10], RMSE: 67.1426\n",
      "Epoch [8/10], RMSE: 66.2390\n",
      "Epoch [9/10], RMSE: 64.4003\n",
      "Epoch [10/10], RMSE: 63.1294\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the input image size and number of spectral bands\n",
    "input_size = (12, 15, 15)\n",
    "\n",
    "# Load a pre-trained ResNet50 model\n",
    "model = models.resnet50(weights='ResNet50_Weights.DEFAULT')\n",
    "\n",
    "# Replace the first convolutional layer to accept input with 12 spectral bands\n",
    "model.conv1 = nn.Conv2d(input_size[0], 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "# Modify the classifier to output the desired number of classes (e.g., 1 for regression)\n",
    "num_classes = 1\n",
    "model.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "# Define a loss function (e.g., mean squared error)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define an optimizer (e.g., Adam) and a learning rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Convert the training data to tensors\n",
    "input_ = torch.from_numpy(train_images).float()\n",
    "output_ = torch.from_numpy(train_biomasses).float().view(-1, 1)\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Pass the input tensor through the model to obtain the predicted output tensor\n",
    "    output_tensor = model(input_)\n",
    "\n",
    "    # Compute the loss between the predicted output tensor and the target tensor\n",
    "    loss = criterion(output_tensor, output_)\n",
    "\n",
    "    # Backpropagate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # Compute the root mean squared error (RMSE) between the predicted output tensor and the target tensor\n",
    "    rmse = torch.sqrt(loss)\n",
    "\n",
    "    # Print the RMSE value for each epoch\n",
    "    print('Epoch [{}/{}], RMSE: {:.4f}'.format(epoch+1, num_epochs, rmse.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 65.59846255300816\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the input size and image dimensions\n",
    "image_size = (12,15, 15)\n",
    "\n",
    "# Define the ResNet50 model and modify its input layer to accept 12 spectral bands\n",
    "resnet = models.resnet50(weights='ResNet50_Weights.DEFAULT')\n",
    "resnet.conv1 = nn.Conv2d(image_size[0], 64, kernel_size=7, stride=2, padding=0, bias=False)\n",
    "\n",
    "# Freeze all layers except for the last one\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "resnet.fc.requires_grad = True\n",
    "\n",
    "# Define the MLPRegressor with one hidden layer of 100 units\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(500,), max_iter=1000)\n",
    "\n",
    "# Use the ResNet50 to extract features from the input images\n",
    "def get_features(input_tensor):\n",
    "    resnet.eval()\n",
    "    with torch.no_grad():\n",
    "        features = resnet(input_tensor)\n",
    "    return features\n",
    "\n",
    "# Extract features from the training input images\n",
    "train_features = get_features(torch.from_numpy(train_images).float())\n",
    "\n",
    "# Train the MLPRegressor using RMSE loss\n",
    "mlp.fit(train_features.numpy(), train_biomasses)\n",
    "\n",
    "# Extract features from the test input images and use the MLPRegressor to predict the output\n",
    "test_features = get_features(torch.from_numpy(validate_images).float())\n",
    "y_pred = mlp.predict(test_features.numpy())\n",
    "\n",
    "# Compute the RMSE loss between the predicted output and the target output\n",
    "rmse = np.sqrt(mean_squared_error(validate_biomasses, y_pred))\n",
    "\n",
    "# Print the RMSE loss value\n",
    "print('RMSE:', rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2_images_h5 = h5py.File(\"images_test.h5\", \"r\")\n",
    "# #prepare test set sentinel 2 images \n",
    "# s2_images = np.array(s2_images_h5[\"images\"])\n",
    "# s2_images = s2_images.transpose(0,3,1,2)\n",
    "\n",
    "## predict on giz test data\n",
    "# pred_giz = pipe.predict(s2_images)\n",
    "# ID_S2_pair = pd.read_csv('/content/UniqueID-SentinelPair.csv')\n",
    "\n",
    "# preds = pd.DataFrame({'Target':pred_giz}).rename_axis('S2_idx').reset_index()\n",
    "# preds = ID_S2_pair.merge(preds, on='S2_idx').drop(columns=['S2_idx'])\n",
    "# preds\n",
    "## preds.to_csv('GIZ_Biomass_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
