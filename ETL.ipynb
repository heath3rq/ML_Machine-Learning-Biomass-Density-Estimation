{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing Image Data for the Africa Biomass Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import urllib.request\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"download images\"\"\"\n",
    "\n",
    "\n",
    "url = \"https://share.phys.ethz.ch/~pf/albecker/abc/09072022_1154_train.h5\"\n",
    "filename = \"trainset.h5\"\n",
    "urllib.request.urlretrieve(url, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"module to load trainset\"\"\"\n",
    "#!wget -q  https://share.phys.ethz.ch/~pf/albecker/abc/09072022_1154_train.h5\n",
    "trainset = h5py.File(\"trainset.h5\", \"r\")\n",
    "\n",
    "# columns\n",
    "data_cols = trainset.keys()\n",
    "print(f\"cols in dataset: {data_cols}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check completeness of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data_cols:\n",
    "    tmp = np.array(trainset[col])\n",
    "    # Check for Nans\n",
    "    mask = np.isnan(tmp) | np.equal(tmp, None)\n",
    "    num_na = np.count_nonzero(mask)\n",
    "    print(f\"{col} : {len(tmp)} values, {num_na} Nans\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">âœ… complete data\n",
    "\n",
    "> agbd stands for Above Ground Biomass Density"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import transform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# shape (25036, 15, 15, 12)\n",
    "images_data = np.array(trainset[\"images\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feature from the VI indices\n",
    "\n",
    "- **NDVI (Normalized Difference Vegetation Index)**: NDVI is widely used for vegetation monitoring and biomass estimation. It is sensitive to the amount and vigor of green vegetation, and has been shown to be strongly correlated with biomass in many studies.\n",
    "\n",
    "- **EVI (Enhanced Vegetation Index)**: EVI is a modified version of NDVI that aims to minimize the effects of atmospheric aerosols and canopy background reflectance. It has been shown to be more effective than NDVI in areas with high biomass, and can be particularly useful for detecting changes in biomass over time.\n",
    "\n",
    "Choice: EVI\n",
    "2.5 * ((NIR - Red) / (NIR + 6 * Red - 7.5 * Blue + 1))\n",
    "\n",
    "where NIR, Red, and Blue are the Near Infrared, Red, and Blue bands, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evi_calc(nir, red, blue):\n",
    "    \"\"\"takes in nir, red, blue values and returns image evi\"\"\"\n",
    "    evi_val = 2.5 * ((nir - red) / (nir + 6 * red - 7.5 * blue + 1))\n",
    "    return evi_val\n",
    "\n",
    "\n",
    "# Extract necessary bands\n",
    "nir_band = images_data[:, :, :, 7]  # 8th band\n",
    "red_band = images_data[:, :, :, 2]  # 3rd band\n",
    "blue_band = images_data[:, :, :, 1]  # 2nd band\n",
    "\n",
    "# Compute EVI for each image\n",
    "evi_data = evi_calc(nir_band, red_band, blue_band)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the images to !224 by 224  64 for now\n",
    "image_data_resized = np.zeros((len(images_data), 64, 64, 12))\n",
    "for i in range(len(images_data)):\n",
    "    for j in range(12):\n",
    "        image_data_resized[i, :, :, j] = transform.resize(\n",
    "            images_data[i, :, :, j], (64, 64)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "image_data_normalized = scaler.fit_transform(image_data_resized.reshape(-1, 12))\n",
    "image_data_normalized = image_data_normalized.reshape((len(images_data), 64, 64, 12))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_data = np.array(trainset[\"cloud\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the images to !224 by 224  64 for now\n",
    "cloud_data_resized = np.zeros((len(cloud_data), 64, 64, 1))\n",
    "for i in range(len(images_data)):\n",
    "    for j in range(1):\n",
    "        image_data_resized[i, :, :, j] = transform.resize(\n",
    "            images_data[i, :, :, j], (64, 64)\n",
    "        )\n",
    "scaler = StandardScaler()\n",
    "cloud_data_normalized = scaler.fit_transform(cloud_data_resized.reshape(-1, 1))\n",
    "cloud_data_normalized = cloud_data_normalized.reshape((len(images_data), 64, 64, 1))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull out bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cloud_data_normalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cloud \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(cloud_data_normalized,(\u001b[39mlen\u001b[39m(cloud_data_normalized,), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m      2\u001b[0m agbd \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(trainset[\u001b[39m\"\u001b[39m\u001b[39magbd\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m latitude \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(trainset[\u001b[39m\"\u001b[39m\u001b[39mlat\u001b[39m\u001b[39m\"\u001b[39m]),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cloud_data_normalized' is not defined"
     ]
    }
   ],
   "source": [
    "cloud = np.reshape(cloud_data_normalized,(len(cloud_data_normalized,), -1))\n",
    "agbd = np.array(trainset[\"agbd\"])\n",
    "latitude = np.array(trainset[\"lat\"]),\n",
    "longitude = np.array(trainset[\"lon\"]),\n",
    "scl = np.array(trainset[\"scl\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Coastal_Aerosol = image_data_normalized[:, :, :, 0].flatten() \n",
    "Blue = image_data_normalized[:, :, :, 1].flatten()\n",
    "Red =  image_data_normalized[:, :, :, 2].flatten()\n",
    "Green = image_data_normalized[:, :, :, 3].flatten()\n",
    "Vegetation_Red_Edge = image_data_normalized[:, :, :, 4].flatten()\n",
    "Vegetation_Red_Edge_2  = image_data_normalized[:, :, :, 5].flatten()\n",
    "Vegetation_Red_Edge_3 = image_data_normalized[:, :, :, 6].flatten()\n",
    "NIR_band = image_data_normalized[:, :, :, 7].flatten()\n",
    "Narrow_NIR = image_data_normalized[:, :, :, 8].flatten()\n",
    "Water_Vapor = image_data_normalized[:, :, :, 9].flatten()\n",
    "Cirrus = image_data_normalized[:, :, :, 10].flatten()\n",
    "SWIR_1_band = image_data_normalized[:, :, :, 11].flatten()\n",
    "SWIR_2_band = image_data_normalized[:, :, :, 12].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "bands = [\"Coastal_Aerosol\", \"Blue\", \"Red\", \"Green\", \"Vegetation_Red_Edge\", \"Vegetation_Red_Edge 2\", \"Vegetation_Red_Edge_3\", \"NIR\", \"Narrow_NIR\", \"Water_Vapor\", \"Cirrus\", \"SWIR_1\", \"SWIR_2\"]\n",
    "\n",
    "for i in range(12):\n",
    "    locals()[bands[i]] = image_data_normalized[:, :, :, i].flatten()\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring all the data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4de7276074beb09e94c04d5e134c141d0f336e3226759f4865dc0d0ce3d2e27e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
